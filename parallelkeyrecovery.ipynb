{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Persisten Faults Attack - Parallel Key Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "```\n",
    "Copyright (C) 2021  Hosein Hadipour\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from faultyaes import *\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import random\n",
    "import itertools\n",
    "from fractions import Fraction\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from os import getpid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "In this experiment we aim to implement the key recovery algorithm (algorithm 3) to see how it works in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Algorithm 2: Find deltaj = skR0 + skRj For Limited Number of Given Ciphertexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delta_candidates(D0, Dj, number_of_faults):    \n",
    "    lambda_prime = len(Dj)\n",
    "    lambda_prime_zero = len(D0)\n",
    "    final_candidates = []\n",
    "    for k in range(lambda_prime_zero - number_of_faults + 1): # Iterating up to this number ensures a non-empty output\n",
    "        candidates = []\n",
    "        delta_counters = dict()\n",
    "        for ell in range(lambda_prime):\n",
    "            alpha_l = D0[k] ^ Dj[ell]\n",
    "            delta_counters[alpha_l] = 1\n",
    "            Dtemp = set(Dj).difference(set([Dj[ell]]))\n",
    "            D0_complement = [d for d in D0 if d != D0[k]]\n",
    "            for d in D0_complement:\n",
    "                E = d ^ alpha_l\n",
    "                if E in Dtemp:\n",
    "                    delta_counters[alpha_l] += 1                    \n",
    "                    Dtemp = Dtemp.difference(set([E]))\n",
    "        candidates = [delta for delta in delta_counters.keys() if delta_counters[delta] >= number_of_faults]\n",
    "        final_candidates.extend(candidates)\n",
    "        final_candidates = list(set(final_candidates))\n",
    "    return final_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Candidates for (K, V)\n",
    "In this experiment we guess the first byte of last round key and determine the remaining key bytes based on the derived candidates for deltaj (where 1 <= j <= 15). \n",
    "\n",
    "\n",
    "Let `D[0] = {d_0, d_1, d_2, ..., d_lambda0}`, then for each key candidate Ki we derive the corresponding set of impossible values according to the following relations:\n",
    "\n",
    "```\n",
    "V = {d_0 + Ki[0], d_1 + Ki[0], ..., d_lambda0 + Ki[0]}\n",
    "```\n",
    "Note that it is oly the first byte of Ki, and the set `D[0]` that are used to derive the corresponding set of impossible values, i.e., Vi.\n",
    "In summary, for each key guess, we have a corresponding set of impossible values which is denoted by Vi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_data_for_key_recovery(number_of_faults, number_of_known_ciphertexts):\n",
    "    reference_set = set(list(range(256)))\n",
    "    ##################################################################\n",
    "    # Initialize a faulty AES for this experiment\n",
    "    observed_bytes = [[[] for _ in range(4)] for _ in range(4)]\n",
    "    non_observed_bytes = [[[] for _ in range(4)] for _ in range(4)]\n",
    "    master_key = random.getrandbits(128)\n",
    "    faulty_aes = AES(master_key)\n",
    "    last_round_key = faulty_aes.round_keys[4*10:4*11]\n",
    "    last_round_key = [last_round_key[j][i] for j in range(4) for i in range(4)]\n",
    "    faulty_aes.apply_fault(number_of_faults)\n",
    "    fault_mapping = faulty_aes.dictionary_of_replacement\n",
    "    known_ciphertexts = []\n",
    "    for this_query in range(number_of_known_ciphertexts):\n",
    "        # Choose a plaintext at random\n",
    "        plaintext = random.getrandbits(128)\n",
    "        ciphertext = faulty_aes.encrypt(plaintext)\n",
    "        known_ciphertexts.append(ciphertext)\n",
    "        ciphertext = text2matrix(ciphertext)\n",
    "        for col in range(4):\n",
    "            for row in range(4):\n",
    "                observed_bytes[col][row].append(ciphertext[col][row])\n",
    "    for col in range(4):\n",
    "        for row in range(4):\n",
    "            observed = set(observed_bytes[col][row])\n",
    "            non_observed_bytes[col][row] = list(reference_set.difference(observed))\n",
    "    ##################################################################\n",
    "    D = [[] for _ in range(16)]\n",
    "    for col in range(4):\n",
    "        for row in range(4):\n",
    "            j = 4*col + row\n",
    "            D[j] = non_observed_bytes[col][row]\n",
    "    delta_candidates = []\n",
    "    for position in range(16):\n",
    "        deltaj = find_delta_candidates(D[0], D[position], number_of_faults=number_of_faults)\n",
    "        delta_candidates.append(deltaj)\n",
    "    all_possible_delta_vectors = list(itertools.product(*delta_candidates))\n",
    "    k_v_candidates = dict()\n",
    "    for sk0 in range(0, 256):\n",
    "        for delta_vector in all_possible_delta_vectors:\n",
    "            k_v_candidates[tuple([sk0 ^ delta for delta in delta_vector])] = [sk0 ^ d for d in D[0]]\n",
    "    return known_ciphertexts, k_v_candidates, last_round_key, fault_mapping, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Function to Divide the Set of Key Candidates into Some Smaller Sub-stes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, num_of_chunks=32):\n",
    "    size_of_each_chunk = len(data) // num_of_chunks\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), size_of_each_chunk):\n",
    "        yield {k:data[k] for k in itertools.islice(it, size_of_each_chunk)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_key_candidates(number_of_faults, fault_mapping, part_of_key_candidates, known_ciphertexts):\n",
    "    counter_Ki_Vi = dict()\n",
    "    # pid = current_process().name\n",
    "    pid = getpid()\n",
    "    progress_var = 0\n",
    "    number_of_candidates = len(part_of_key_candidates)\n",
    "    aes_instance = AES(0)\n",
    "    aes_instance.apply_fault(number_of_faults=number_of_faults, fault_mapping=fault_mapping)\n",
    "    for Ki in part_of_key_candidates.keys():\n",
    "        if progress_var % 50 == 0:\n",
    "            print(f\"process id: {pid}, candidates no {progress_var} / {number_of_candidates}\")\n",
    "        counter_Ki_Vi[Ki] = 0\n",
    "        Ki_matrix = [[Ki[i + 4*j] for i in range(4)] for j in range(4)]\n",
    "        aes_instance.derive_round_keys_from_last_round_key(Ki_matrix)\n",
    "        for this_cipher in known_ciphertexts:\n",
    "            counter_Ki_Vi[Ki] += aes_instance.decrypt_and_count1(this_cipher, part_of_key_candidates[Ki])\n",
    "        progress_var += 1\n",
    "    return counter_Ki_Vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_cnt_for_wrong_and_correct_keys(number_of_faults=4, number_of_independent_experiments=10, num_of_processes=16):\n",
    "    m = 256 - number_of_faults\n",
    "    number_of_known_ciphertexts = int(np.ceil(m*harmonic_number(m)))\n",
    "    number_of_derived_keys = []\n",
    "    cnt_of_correct_keys = []\n",
    "    all_cnt_of_wrong_keys = []\n",
    "    true_and_retrievd_last_round_keys = dict()\n",
    "    for nxp in range(number_of_independent_experiments):\n",
    "        D = [[]]\n",
    "        while len(D[0]) != number_of_faults:\n",
    "            known_ciphertexts, k_v_candidates, last_round_key, fault_mapping, D = generate_input_data_for_key_recovery(number_of_faults, number_of_known_ciphertexts)\n",
    "        counter_Ki_Vi = dict()\n",
    "        number_of_candidates = len(k_v_candidates.keys())\n",
    "        print(\"Number of faults: %d, Number of known ciphertexts: %d, Number of key candidates: %d\" %\\\n",
    "             (number_of_faults, len(known_ciphertexts), number_of_candidates))\n",
    "\n",
    "        # Divide the set of key candidates into some smaller chunks\n",
    "        k_v_candidates_chunks = list(chunks(k_v_candidates, num_of_chunks=num_of_processes))\n",
    "\n",
    "        print(\"----------------- START KEY RECOVERY -----------------\")\n",
    "        start_time = time.time()\n",
    "        # Parallel execution\n",
    "        with Pool(len(k_v_candidates_chunks)) as pool:\n",
    "            arguments = [(number_of_faults, fault_mapping, k_v_chunk, known_ciphertexts)\\\n",
    "                for k_v_chunk in k_v_candidates_chunks]\n",
    "            results = pool.starmap(check_key_candidates, arguments)\n",
    "        # End of parallel execution\n",
    "\n",
    "        # Collect the outputs of parallel processes\n",
    "        for output in results:\n",
    "            counter_Ki_Vi.update(output)\n",
    "        \n",
    "        max_cnt = max(counter_Ki_Vi.values())\n",
    "        derived_keys = [K for K in counter_Ki_Vi.keys() if counter_Ki_Vi[K] == max_cnt]\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"Time used by key recovery: %0.2f Seconds, experiment no %2d\" % (elapsed_time, nxp))\n",
    "        print(\"------------- KEY RECOVERY WAS FINISHED -------------\")\n",
    "        \n",
    "        number_of_derived_keys.append(len(derived_keys))\n",
    "        cnt_of_correct_keys.append(max_cnt)\n",
    "        cnts_of_wrong_keys = [cnt for cnt in counter_Ki_Vi.values() if cnt != max_cnt]\n",
    "        all_cnt_of_wrong_keys.extend(cnts_of_wrong_keys)\n",
    "        true_and_retrievd_last_round_keys[derived_keys[0]] = last_round_key\n",
    "    output_dict = dict()\n",
    "    output_dict[\"cnt_of_correct_keys\"] = cnt_of_correct_keys\n",
    "    output_dict[\"all_cnt_of_wrong_keys\"] = all_cnt_of_wrong_keys\n",
    "    output_dict[\"avg_number_of_derived_keys\"] = mean(number_of_derived_keys)\n",
    "    output_dict[\"avg_cnt_of_correct_keys\"] = mean(cnt_of_correct_keys)\n",
    "    output_dict[\"avg_cnt_of_wrong_keys\"] = mean(all_cnt_of_wrong_keys)\n",
    "    return true_and_retrievd_last_round_keys, output_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_and_retrievd_last_round_keys, output_dict =\\\n",
    "#      compute_avg_cnt_for_wrong_and_correct_keys(number_of_faults=5, number_of_independent_experiments=2, num_of_processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dict[\"avg_number_of_derived_keys\"], \\\n",
    "# output_dict[\"avg_cnt_of_correct_keys\"], \\\n",
    "# output_dict[\"avg_cnt_of_wrong_keys\"], \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in the main code. Process name is: __main__\n",
      "Number of faults: 3, Number of known ciphertexts: 1547, Number of key candidates: 256\n",
      "----------------- START KEY RECOVERY -----------------\n",
      "process id: 9393, candidates no 0 / 8process id: 9392, candidates no 0 / 8process id: 9391, candidates no 0 / 8process id: 9396, candidates no 0 / 8\n",
      "\n",
      "process id: 9397, candidates no 0 / 8process id: 9398, candidates no 0 / 8process id: 9400, candidates no 0 / 8\n",
      "process id: 9401, candidates no 0 / 8\n",
      "process id: 9404, candidates no 0 / 8process id: 9405, candidates no 0 / 8process id: 9395, candidates no 0 / 8process id: 9403, candidates no 0 / 8\n",
      "\n",
      "process id: 9406, candidates no 0 / 8process id: 9416, candidates no 0 / 8process id: 9408, candidates no 0 / 8process id: 9411, candidates no 0 / 8process id: 9409, candidates no 0 / 8\n",
      "process id: 9407, candidates no 0 / 8process id: 9394, candidates no 0 / 8process id: 9414, candidates no 0 / 8\n",
      "\n",
      "\n",
      "\n",
      "process id: 9417, candidates no 0 / 8\n",
      "\n",
      "process id: 9418, candidates no 0 / 8process id: 9402, candidates no 0 / 8process id: 9419, candidates no 0 / 8process id: 9399, candidates no 0 / 8process id: 9422, candidates no 0 / 8process id: 9421, candidates no 0 / 8process id: 9415, candidates no 0 / 8\n",
      "process id: 9412, candidates no 0 / 8process id: 9410, candidates no 0 / 8\n",
      "process id: 9413, candidates no 0 / 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "process id: 9420, candidates no 0 / 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Time used by key recovery: 9.27 Seconds, experiment no  0\n",
      "------------- KEY RECOVERY WAS FINISHED -------------\n",
      "Number of derived keys:  1, Counter of correct key:    10643, Counter of wrong key:     6093\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Now in the main code. Process name is:', __name__)\n",
    "    flag = 'compute_data'\n",
    "    if flag == 'compute_data':\n",
    "        results = compute_avg_cnt_for_wrong_and_correct_keys(number_of_faults=3, number_of_independent_experiments=1, num_of_processes=32)\n",
    "        with open('output_lambda_2', 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        print(\"Number of derived keys: %2d, Counter of correct key: %8d, Counter of wrong key: %8d\" % \n",
    "        (results[1][\"avg_number_of_derived_keys\"], \\\n",
    "        results[1][\"avg_cnt_of_correct_keys\"], \\\n",
    "        results[1][\"avg_cnt_of_wrong_keys\"]))\n",
    "    elif flag == 'read_data':\n",
    "        with open('output_lambda_2', 'rb') as f:\n",
    "            results = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
